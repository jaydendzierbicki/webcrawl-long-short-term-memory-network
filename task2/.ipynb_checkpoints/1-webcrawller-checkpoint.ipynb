{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "267a3334",
   "metadata": {},
   "source": [
    "# 1-Webcrawller Script\n",
    "Date created: 13-04-2023  \n",
    "Created by: Jayden Dzierbicki  \n",
    "Last updated: 14-04-2023  \n",
    "\n",
    "The purpose of this notebook is to collect data on XRP, a cryptocurrency, from two different sources: historic price data and forum posts. The notebook scrapes data from the following websites:\n",
    "\n",
    "- https://finance.yahoo.com/quote/XRP-AUD/history?p=XRP-AUD (for XRP price in AUD)\n",
    "- https://www.cryptocompare.com/coins/xrp/forum (for XRP forum posts)\n",
    "- https://www.investing.com/crypto/xrp/chat (for XRP forum posts)\n",
    "\n",
    "All collected data is stored in a mySQL database. A CSV backup of the data is also created and saved to the task1 folder with this notebook.\n",
    "\n",
    "It's important to note that the mySQL database schema includes tables for both price data and forum posts, with column names and data types specified for each. While this script only collects data from two sources, it demonstrates how web scraping can be used to collect data from multiple sources and store it in a database for analysis.\n",
    "\n",
    "One potential issue with this data collection process is that there may be biases in the forum posts that are collected, as they are only from two websites. Additionally, there may be technical challenges in scraping the data from these websites. By acknowledging these limitations, readers can better interpret the data and its potential biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "781cb8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requirments to work\n",
    "import time # Provides time-related functions\n",
    "from datetime import datetime, timedelta, date # Provides date and time-related functions\n",
    "from bs4 import BeautifulSoup # For parsing HTML and XML documents\n",
    "import pandas as pd # For data manipulation and analysis\n",
    "import dateparser # For parsing date strings\n",
    "from selenium import webdriver # For automated web testing\n",
    "from selenium.webdriver.common.keys import Keys # For simulating keyboard keys\n",
    "from selenium.webdriver.chrome.options import Options # For setting up Chrome options\n",
    "from tqdm import tqdm # For displaying progress bars\n",
    "import getpass # For getting a password without displaying it on the screen\n",
    "from sqlalchemy import create_engine # For connecting to SQL databases\n",
    "from yahoo_fin.stock_info import get_data # For getting historical stock data from Yahoo Finance\n",
    "\n",
    "\n",
    "# Function to load data into mySQL\n",
    "def load_data_mySQL(database_name, table_name, df):\n",
    "    user = 'root'\n",
    "\n",
    "    # Prompt the user for a password\n",
    "    password = getpass.getpass(\"Enter your MySQL password: \")\n",
    "    host = 'localhost'\n",
    "    port = 3306\n",
    "    database = database_name\n",
    "    engine = create_engine(f\"mysql+pymysql://{user}:{password}@{host}:{port}/{database}\")\n",
    "\n",
    "    # Write the DataFrame to a SQL table\n",
    "    table_name =  table_name\n",
    "    df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "\n",
    "    # Close the connection\n",
    "    engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c1e653",
   "metadata": {},
   "source": [
    "## cryptocompare.com crawler\n",
    "Will need to undergo a simple ETL proccess\n",
    "- Step 1: Extract data from cryptocompare.com\n",
    "- Step 2: Transform data in prepration for initial storage (add ID, convert datetime to date and time)\n",
    "- Step 3: Load data into mySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "debf43cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Data\n",
    "\n",
    "class cryptocompareCrawler():\n",
    "    def __init__(self, start_link):\n",
    "        self.link_to_explore = start_link\n",
    "        self.comments = pd.DataFrame(columns=['date', 'comment'])\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        self.driver = webdriver.Chrome(executable_path='C:/webdrivers/chromedriver', options=chrome_options)\n",
    "        self.pagecount = 1\n",
    "        self.next = True\n",
    "\n",
    "    def run(self):\n",
    "        try:\n",
    "            post_data = self.scrape_crypto_forum(self.link_to_explore)\n",
    "            self.extract_data(post_data)\n",
    "            self.save_data_to_file()\n",
    "        except:\n",
    "            print(\"Cannot get the page \" + self.link_to_explore)\n",
    "            raise\n",
    "            \n",
    "\n",
    "    def scrape_crypto_forum(self, url, scroll_duration=timedelta(hours=1)):\n",
    "        self.driver.get(url)\n",
    "\n",
    "        scroll_interval = 6\n",
    "        total_iterations = int(scroll_duration.total_seconds() // scroll_interval)\n",
    "\n",
    "        progress_bar = tqdm(range(total_iterations),  dynamic_ncols=True, desc=\"Scraping posts\")\n",
    "\n",
    "        start_time = datetime.now()\n",
    "        post_data = []\n",
    "        prev_post_count = 0\n",
    "        iteration = 0\n",
    "        while iteration < total_iterations:\n",
    "            self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(scroll_interval)\n",
    "\n",
    "            html_content = self.driver.page_source\n",
    "            soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "            posts = soup.find_all(\"div\", {\"class\": \"post-content\"})\n",
    "\n",
    "            if len(posts) > prev_post_count:\n",
    "                for post in posts[prev_post_count:]:\n",
    "                    comment_element = post.find(\"div\", {\"class\": \"content-body\"})\n",
    "                    date_element = post.find(\"div\", {\"class\": \"item-ago ng-binding\"})\n",
    "                    if comment_element and date_element:\n",
    "                        date_str = date_element['title']\n",
    "                        parsed_date = dateparser.parse(date_str, settings={\"RELATIVE_BASE\": datetime.now()})\n",
    "                        comment = comment_element.text.replace('\\n', '').strip()\n",
    "                        post_data.append({\"comment\": comment, \"date\": parsed_date})\n",
    "\n",
    "                prev_post_count = len(posts)\n",
    "\n",
    "            iteration += 1\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        progress_bar.close()\n",
    "        return post_data\n",
    "\n",
    "    def extract_data(self, post_data):\n",
    "        for data in post_data:\n",
    "            comment_str = data['comment']\n",
    "            standardized_date = data['date'].strftime('%Y-%m-%d %H:%M:%S')\n",
    "            self.comments.loc[len(self.comments)] = [standardized_date, comment_str]\n",
    "\n",
    "    def save_data_to_file(self):\n",
    "        today_date = datetime.today().strftime('%Y-%m-%d')\n",
    "        self.comments.to_csv(f'cryptocompare_{today_date}.csv', index=False)\n",
    "\n",
    "    def close_spider(self):\n",
    "        self.driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab681f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayde\\AppData\\Local\\Temp/ipykernel_20188/553188809.py:9: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  self.driver = webdriver.Chrome(executable_path='C:/webdrivers/chromedriver', options=chrome_options)\n",
      "\n",
      "\n",
      "Scraping posts:   0%|                                                                          | 0/600 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   0%|                                                                | 1/600 [00:06<1:04:53,  6.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   0%|▏                                                               | 2/600 [00:13<1:05:14,  6.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   0%|▎                                                               | 3/600 [00:19<1:05:52,  6.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   1%|▍                                                               | 4/600 [00:26<1:06:42,  6.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   1%|▌                                                               | 5/600 [00:33<1:07:50,  6.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   1%|▋                                                               | 6/600 [00:41<1:09:29,  7.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   0%|▏                                                           | 1/400 [33:13<220:59:17, 1993.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Scraping posts:   1%|▊                                                               | 8/600 [00:59<1:22:36,  8.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   2%|▉                                                               | 9/600 [01:07<1:20:07,  8.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   2%|█                                                              | 10/600 [01:15<1:19:31,  8.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   2%|█▏                                                             | 11/600 [01:24<1:22:31,  8.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   2%|█▎                                                             | 12/600 [01:32<1:21:50,  8.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   2%|█▎                                                             | 13/600 [01:41<1:24:37,  8.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   2%|█▍                                                             | 14/600 [01:50<1:24:20,  8.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   2%|█▌                                                             | 15/600 [02:00<1:27:51,  9.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   3%|█▋                                                             | 16/600 [02:09<1:27:46,  9.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   3%|█▊                                                             | 17/600 [02:19<1:31:11,  9.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   3%|█▉                                                             | 18/600 [02:28<1:31:16,  9.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   3%|█▉                                                             | 19/600 [02:39<1:34:53,  9.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   3%|██                                                             | 20/600 [02:50<1:38:02, 10.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   4%|██▏                                                            | 21/600 [03:00<1:37:56, 10.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   4%|██▎                                                            | 22/600 [03:12<1:41:40, 10.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   4%|██▍                                                            | 23/600 [03:24<1:44:56, 10.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   4%|██▌                                                            | 24/600 [03:35<1:47:28, 11.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   4%|██▋                                                            | 25/600 [03:46<1:46:54, 11.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   4%|██▋                                                            | 26/600 [03:59<1:51:24, 11.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   4%|██▊                                                            | 27/600 [04:12<1:53:41, 11.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   5%|██▉                                                            | 28/600 [04:25<1:56:47, 12.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   5%|███                                                            | 29/600 [04:37<1:56:27, 12.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   5%|███▏                                                           | 30/600 [04:51<2:00:49, 12.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   5%|███▎                                                           | 31/600 [05:05<2:04:22, 13.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   5%|███▎                                                           | 32/600 [05:19<2:07:12, 13.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   6%|███▍                                                           | 33/600 [05:34<2:09:49, 13.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   6%|███▌                                                           | 34/600 [05:48<2:10:30, 13.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   6%|███▋                                                           | 35/600 [06:02<2:13:00, 14.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   6%|███▊                                                           | 36/600 [06:17<2:13:23, 14.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   6%|███▉                                                           | 37/600 [06:34<2:21:17, 15.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   6%|███▉                                                           | 38/600 [06:49<2:22:39, 15.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   6%|████                                                           | 39/600 [07:07<2:29:44, 16.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   7%|████▏                                                          | 40/600 [07:23<2:27:28, 15.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   7%|████▎                                                          | 41/600 [07:41<2:34:36, 16.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   7%|████▍                                                          | 42/600 [07:57<2:31:09, 16.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   7%|████▌                                                          | 43/600 [08:15<2:36:11, 16.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   7%|████▌                                                          | 44/600 [08:32<2:37:34, 17.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   8%|████▋                                                          | 45/600 [08:48<2:35:36, 16.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   8%|████▊                                                          | 46/600 [09:08<2:44:00, 17.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   8%|████▉                                                          | 47/600 [09:27<2:46:55, 18.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   8%|█████                                                          | 48/600 [09:47<2:50:04, 18.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   8%|█████▏                                                         | 49/600 [10:07<2:54:11, 18.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   8%|█████▎                                                         | 50/600 [10:28<2:59:08, 19.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   8%|█████▎                                                         | 51/600 [10:49<3:04:42, 20.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   9%|█████▍                                                         | 52/600 [11:10<3:06:38, 20.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   9%|█████▌                                                         | 53/600 [11:32<3:08:11, 20.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   9%|█████▋                                                         | 54/600 [11:54<3:13:43, 21.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   9%|█████▊                                                         | 55/600 [12:17<3:15:54, 21.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:   9%|█████▉                                                         | 56/600 [12:39<3:17:28, 21.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:  10%|█████▉                                                         | 57/600 [13:02<3:21:40, 22.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "Scraping posts:  10%|██████                                                         | 58/600 [13:27<3:27:21, 22.96s/it]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "# Extract data\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "\n",
    "# Initialize the class with the base URL\n",
    "crawler = cryptocompareCrawler('https://www.cryptocompare.com/coins/xrp/forum')\n",
    "\n",
    "# Run the crawler\n",
    "crawler.run()\n",
    "\n",
    "# Close the spider\n",
    "crawler.close_spider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfe381e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>comment</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>moon soon, coon. mark my words (lol idk - no f...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.cryptocompare.com/coins/xrp/forum</td>\n",
       "      <td>08:41:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>Boring xrp at the Moment</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.cryptocompare.com/coins/xrp/forum</td>\n",
       "      <td>02:27:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>So bankrupted FTX….they recover $7.3 billion i...</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.cryptocompare.com/coins/xrp/forum</td>\n",
       "      <td>01:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-13</td>\n",
       "      <td>Is UMU what many thought XRP was going to be u...</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.cryptocompare.com/coins/xrp/forum</td>\n",
       "      <td>19:11:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-13</td>\n",
       "      <td>Coinbase just deposited Flare into my account....</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.cryptocompare.com/coins/xrp/forum</td>\n",
       "      <td>00:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6397</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>I somewhat feel sorry for the newcommers. I gu...</td>\n",
       "      <td>6398</td>\n",
       "      <td>https://www.cryptocompare.com/coins/xrp/forum</td>\n",
       "      <td>02:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6398</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>Veyor..MGI</td>\n",
       "      <td>6399</td>\n",
       "      <td>https://www.cryptocompare.com/coins/xrp/forum</td>\n",
       "      <td>02:28:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6399</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>big jump in ODL volume since the sec lawsuitis...</td>\n",
       "      <td>6400</td>\n",
       "      <td>https://www.cryptocompare.com/coins/xrp/forum</td>\n",
       "      <td>02:27:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6400</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>Funny how humans brain works. In fomo Times ev...</td>\n",
       "      <td>6401</td>\n",
       "      <td>https://www.cryptocompare.com/coins/xrp/forum</td>\n",
       "      <td>02:11:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6401</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>The long term XRP holders benefited at the end...</td>\n",
       "      <td>6402</td>\n",
       "      <td>https://www.cryptocompare.com/coins/xrp/forum</td>\n",
       "      <td>02:02:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6402 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                            comment    id  \\\n",
       "0     2023-04-14  moon soon, coon. mark my words (lol idk - no f...     1   \n",
       "1     2023-04-14                           Boring xrp at the Moment     2   \n",
       "2     2023-04-14  So bankrupted FTX….they recover $7.3 billion i...     3   \n",
       "3     2023-04-13  Is UMU what many thought XRP was going to be u...     4   \n",
       "4     2023-04-13  Coinbase just deposited Flare into my account....     5   \n",
       "...          ...                                                ...   ...   \n",
       "6397  2021-02-02  I somewhat feel sorry for the newcommers. I gu...  6398   \n",
       "6398  2021-02-02                                         Veyor..MGI  6399   \n",
       "6399  2021-02-02  big jump in ODL volume since the sec lawsuitis...  6400   \n",
       "6400  2021-02-02  Funny how humans brain works. In fomo Times ev...  6401   \n",
       "6401  2021-02-02  The long term XRP holders benefited at the end...  6402   \n",
       "\n",
       "                                             source      time  \n",
       "0     https://www.cryptocompare.com/coins/xrp/forum  08:41:00  \n",
       "1     https://www.cryptocompare.com/coins/xrp/forum  02:27:00  \n",
       "2     https://www.cryptocompare.com/coins/xrp/forum  01:20:00  \n",
       "3     https://www.cryptocompare.com/coins/xrp/forum  19:11:00  \n",
       "4     https://www.cryptocompare.com/coins/xrp/forum  00:49:00  \n",
       "...                                             ...       ...  \n",
       "6397  https://www.cryptocompare.com/coins/xrp/forum  02:30:00  \n",
       "6398  https://www.cryptocompare.com/coins/xrp/forum  02:28:00  \n",
       "6399  https://www.cryptocompare.com/coins/xrp/forum  02:27:00  \n",
       "6400  https://www.cryptocompare.com/coins/xrp/forum  02:11:00  \n",
       "6401  https://www.cryptocompare.com/coins/xrp/forum  02:02:00  \n",
       "\n",
       "[6402 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trasnform Data \n",
    "\n",
    "# Add an ID column to the DataFrame\n",
    "df = pd.read_csv(f'cryptocompare_2023-04-15.csv')\n",
    "df['id'] = df.index + 1\n",
    "df['source'] = 'https://www.cryptocompare.com/coins/xrp/forum'\n",
    "df[['date', 'time']] = df['date'].str.split(' ', n=1, expand=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f563761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your MySQL password: ········\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "load_data_mySQL('MA5851_A3', 'cryptocompare_xrp', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc58ad6d",
   "metadata": {},
   "source": [
    "## Investing.com crawler\n",
    "Will need to undergo a simple ETL proccess\n",
    "- Step 1: Extract data from Investing.com\n",
    "- Step 2: Transform data in prepration for initial storage (add ID, convert datetime to date and time)\n",
    "- Step 3: Load data into mySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "567df8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to extract data\n",
    "# Scrape https://www.investing.com/crypto/xrp/chat \n",
    "# Need to crawl multiple pages over 1200 pages! with data from 2019\n",
    "\n",
    "class investingCrawler():\n",
    "    def __init__(self, start_link):\n",
    "        self.link_to_explore = start_link\n",
    "        self.comments = pd.DataFrame(columns = ['date','comment'])\n",
    "        self.driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)           \n",
    "        self.pagecount = 1\n",
    "        self.next = True\n",
    "        \n",
    "    def run(self):\n",
    "        with tqdm(total=1222, dynamic_ncols=True, desc=\"Scraping posts\") as pbar:\n",
    "            while self.next:\n",
    "                if self.pagecount >= 1222:\n",
    "                    self.save_data_to_file()\n",
    "                    self.next = False\n",
    "                try:\n",
    "                    self.driver.get(self.link_to_explore + \"/\" + str(self.pagecount))\n",
    "                    self.driver.implicitly_wait(15)\n",
    "                    self.extract_data()      \n",
    "                    self.pagecount = self.pagecount + 1\n",
    "                    pbar.update(1)\n",
    "                except:\n",
    "                    print (\"Cannot get the page \" + self.link_to_explore)\n",
    "                    self.next = False\n",
    "                    raise\n",
    "\n",
    "    def extract_data(self):\n",
    "        html_content = self.driver.page_source\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "        comment_wrappers = soup.find_all(\"div\", {\"class\": \"commentInnerWrapper\"})\n",
    "\n",
    "        count = 0\n",
    "        for wrapper in comment_wrappers:\n",
    "            date_element = wrapper.find(\"span\", {\"class\": \"js-date\"})\n",
    "            date_str = date_element[\"comment-date-formatted\"]\n",
    "\n",
    "            # Parse date string and convert it to a standardized format\n",
    "            parsed_date = dateparser.parse(date_str)\n",
    "            standardized_date = parsed_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            comment_element = wrapper.find(\"span\", {\"class\": \"js-text\"})\n",
    "            comment_str = comment_element.text.strip()\n",
    "\n",
    "            # Adding date and comment to the dataframe\n",
    "            self.comments.loc[len(self.comments)] = [standardized_date, comment_str]\n",
    "            count += 1\n",
    "\n",
    "        return count\n",
    "\n",
    "\n",
    "\n",
    "    def save_data_to_file(self):\n",
    "    #we save the dataframe content to a CSV file\n",
    "        today_date = date.today()\n",
    "        self.comments.to_csv(f'investing_{today_date}.csv', index=False)\n",
    "    def close_spider(self):\n",
    "    #end the session\n",
    "        self.driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29fd610f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayde\\AppData\\Local\\Temp/ipykernel_27308/3816390378.py:9: DeprecationWarning: use options instead of chrome_options\n",
      "  self.driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
      "Scraping posts: 100%|██████████████████████████████████████████████████████████████| 1222/1222 [41:11<00:00,  2.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# Extract data\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "\n",
    "# Initialize the class with the base URL\n",
    "crawler = investingCrawler('https://www.investing.com/crypto/xrp/chat')\n",
    "\n",
    "# Run the crawler\n",
    "crawler.run()\n",
    "\n",
    "# Close the spider\n",
    "crawler.close_spider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ab23a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>comment</th>\n",
       "      <th>time</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>Still a bargain. Regards.</td>\n",
       "      <td>12:15:57</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.investing.com/crypto/xrp/chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-12</td>\n",
       "      <td>btc going higher so will this</td>\n",
       "      <td>23:10:00</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.investing.com/crypto/xrp/chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-12</td>\n",
       "      <td>Going back down to .40. No settlement. Market ...</td>\n",
       "      <td>14:39:00</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.investing.com/crypto/xrp/chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-12</td>\n",
       "      <td>$1</td>\n",
       "      <td>11:01:00</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.investing.com/crypto/xrp/chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-12</td>\n",
       "      <td>Back to sick</td>\n",
       "      <td>07:57:00</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.investing.com/crypto/xrp/chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59743</th>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>Same happened in 2013 ....many sold and few go...</td>\n",
       "      <td>03:29:00</td>\n",
       "      <td>59744</td>\n",
       "      <td>https://www.investing.com/crypto/xrp/chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59744</th>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>Sell it off before it’s too late</td>\n",
       "      <td>15:22:00</td>\n",
       "      <td>59745</td>\n",
       "      <td>https://www.investing.com/crypto/xrp/chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59745</th>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>No more up for crypto</td>\n",
       "      <td>15:22:00</td>\n",
       "      <td>59746</td>\n",
       "      <td>https://www.investing.com/crypto/xrp/chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59746</th>\n",
       "      <td>2018-03-16</td>\n",
       "      <td>Now cardano it's going to ********up anytime!</td>\n",
       "      <td>18:43:00</td>\n",
       "      <td>59747</td>\n",
       "      <td>https://www.investing.com/crypto/xrp/chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59747</th>\n",
       "      <td>2018-03-16</td>\n",
       "      <td>Anything , a week ? A month ? Or year? ..</td>\n",
       "      <td>18:43:00</td>\n",
       "      <td>59748</td>\n",
       "      <td>https://www.investing.com/crypto/xrp/chat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59748 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date                                            comment  \\\n",
       "0      2023-04-14                          Still a bargain. Regards.   \n",
       "1      2023-04-12                      btc going higher so will this   \n",
       "2      2023-04-12  Going back down to .40. No settlement. Market ...   \n",
       "3      2023-04-12                                                 $1   \n",
       "4      2023-04-12                                       Back to sick   \n",
       "...           ...                                                ...   \n",
       "59743  2018-03-18  Same happened in 2013 ....many sold and few go...   \n",
       "59744  2018-03-17                   Sell it off before it’s too late   \n",
       "59745  2018-03-17                              No more up for crypto   \n",
       "59746  2018-03-16      Now cardano it's going to ********up anytime!   \n",
       "59747  2018-03-16          Anything , a week ? A month ? Or year? ..   \n",
       "\n",
       "           time     id                                     source  \n",
       "0      12:15:57      1  https://www.investing.com/crypto/xrp/chat  \n",
       "1      23:10:00      2  https://www.investing.com/crypto/xrp/chat  \n",
       "2      14:39:00      3  https://www.investing.com/crypto/xrp/chat  \n",
       "3      11:01:00      4  https://www.investing.com/crypto/xrp/chat  \n",
       "4      07:57:00      5  https://www.investing.com/crypto/xrp/chat  \n",
       "...         ...    ...                                        ...  \n",
       "59743  03:29:00  59744  https://www.investing.com/crypto/xrp/chat  \n",
       "59744  15:22:00  59745  https://www.investing.com/crypto/xrp/chat  \n",
       "59745  15:22:00  59746  https://www.investing.com/crypto/xrp/chat  \n",
       "59746  18:43:00  59747  https://www.investing.com/crypto/xrp/chat  \n",
       "59747  18:43:00  59748  https://www.investing.com/crypto/xrp/chat  \n",
       "\n",
       "[59748 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform data\n",
    "df = pd.read_csv(f'investing_2023-04-14.csv')\n",
    "\n",
    "# Split the date and time values into separate columns\n",
    "df[['date', 'time']] = df['date'].str.split(' ', n=1, expand=True)\n",
    "\n",
    "# Add an ID column & source URL to the DataFrame\n",
    "df['id'] = df.index + 1\n",
    "df['source'] = 'https://www.investing.com/crypto/xrp/chat'\n",
    "\n",
    "# Print to confrim looks correct\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a22b5412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your MySQL password: ········\n"
     ]
    }
   ],
   "source": [
    "# Load data to mySQL ready for task 2\n",
    "load_data_mySQL('MA5851_A3', 'investingcom_xrp', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b261214e",
   "metadata": {},
   "source": [
    "## Yahoofinance.com price extraction\n",
    "Yahoo provide API and tools to obtain data which is much more efficent then scrapping via a built in function for python\n",
    "Will need to undergo a simple ETL proccess\n",
    "- Step 1: Extract data from yahoofinance.com\n",
    "- Step 2: Transform data in prepration for initial storage (add ID, convert datetime to date and time)\n",
    "- Step 3: Load data into mySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c888d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data\n",
    "\n",
    "df= get_data(\"XRP-AUD\", start_date=\"01/01/2017\", end_date=\"15/04/2023\", index_as_date = False, interval=\"1d\")\n",
    "today_date = date.today()\n",
    "df.to_csv(f'xrp_price_yahoo_{today_date}.csv', index=False) #backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e457e0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-10</td>\n",
       "      <td>0.284150</td>\n",
       "      <td>0.285022</td>\n",
       "      <td>0.267963</td>\n",
       "      <td>0.269525</td>\n",
       "      <td>0.269525</td>\n",
       "      <td>184092145</td>\n",
       "      <td>XRP-AUD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>0.268827</td>\n",
       "      <td>0.279932</td>\n",
       "      <td>0.268188</td>\n",
       "      <td>0.274677</td>\n",
       "      <td>0.274677</td>\n",
       "      <td>175568474</td>\n",
       "      <td>XRP-AUD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-12</td>\n",
       "      <td>0.274395</td>\n",
       "      <td>0.274395</td>\n",
       "      <td>0.255044</td>\n",
       "      <td>0.258094</td>\n",
       "      <td>0.258094</td>\n",
       "      <td>328505111</td>\n",
       "      <td>XRP-AUD</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-13</td>\n",
       "      <td>0.258268</td>\n",
       "      <td>0.267999</td>\n",
       "      <td>0.258315</td>\n",
       "      <td>0.267195</td>\n",
       "      <td>0.267195</td>\n",
       "      <td>174109535</td>\n",
       "      <td>XRP-AUD</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>0.267506</td>\n",
       "      <td>0.280253</td>\n",
       "      <td>0.267401</td>\n",
       "      <td>0.275036</td>\n",
       "      <td>0.275036</td>\n",
       "      <td>166943243</td>\n",
       "      <td>XRP-AUD</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>0.757934</td>\n",
       "      <td>0.763103</td>\n",
       "      <td>0.750791</td>\n",
       "      <td>0.758037</td>\n",
       "      <td>0.758037</td>\n",
       "      <td>825097347</td>\n",
       "      <td>XRP-AUD</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>0.757976</td>\n",
       "      <td>0.782039</td>\n",
       "      <td>0.752795</td>\n",
       "      <td>0.779685</td>\n",
       "      <td>0.779685</td>\n",
       "      <td>1375478642</td>\n",
       "      <td>XRP-AUD</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>2023-04-12</td>\n",
       "      <td>0.779669</td>\n",
       "      <td>0.788820</td>\n",
       "      <td>0.772128</td>\n",
       "      <td>0.777849</td>\n",
       "      <td>0.777849</td>\n",
       "      <td>1813207929</td>\n",
       "      <td>XRP-AUD</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>2023-04-13</td>\n",
       "      <td>0.777921</td>\n",
       "      <td>0.778733</td>\n",
       "      <td>0.749323</td>\n",
       "      <td>0.755734</td>\n",
       "      <td>0.755734</td>\n",
       "      <td>1587786706</td>\n",
       "      <td>XRP-AUD</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>0.756334</td>\n",
       "      <td>0.802178</td>\n",
       "      <td>0.755051</td>\n",
       "      <td>0.785260</td>\n",
       "      <td>0.785260</td>\n",
       "      <td>2380426240</td>\n",
       "      <td>XRP-AUD</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date      open      high       low     close  adjclose      volume  \\\n",
       "0    2017-11-10  0.284150  0.285022  0.267963  0.269525  0.269525   184092145   \n",
       "1    2017-11-11  0.268827  0.279932  0.268188  0.274677  0.274677   175568474   \n",
       "2    2017-11-12  0.274395  0.274395  0.255044  0.258094  0.258094   328505111   \n",
       "3    2017-11-13  0.258268  0.267999  0.258315  0.267195  0.267195   174109535   \n",
       "4    2017-11-14  0.267506  0.280253  0.267401  0.275036  0.275036   166943243   \n",
       "...         ...       ...       ...       ...       ...       ...         ...   \n",
       "1977 2023-04-10  0.757934  0.763103  0.750791  0.758037  0.758037   825097347   \n",
       "1978 2023-04-11  0.757976  0.782039  0.752795  0.779685  0.779685  1375478642   \n",
       "1979 2023-04-12  0.779669  0.788820  0.772128  0.777849  0.777849  1813207929   \n",
       "1980 2023-04-13  0.777921  0.778733  0.749323  0.755734  0.755734  1587786706   \n",
       "1981 2023-04-14  0.756334  0.802178  0.755051  0.785260  0.785260  2380426240   \n",
       "\n",
       "       ticker    id  \n",
       "0     XRP-AUD     1  \n",
       "1     XRP-AUD     2  \n",
       "2     XRP-AUD     3  \n",
       "3     XRP-AUD     4  \n",
       "4     XRP-AUD     5  \n",
       "...       ...   ...  \n",
       "1977  XRP-AUD  1978  \n",
       "1978  XRP-AUD  1979  \n",
       "1979  XRP-AUD  1980  \n",
       "1980  XRP-AUD  1981  \n",
       "1981  XRP-AUD  1982  \n",
       "\n",
       "[1982 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform data\n",
    "# Add an ID column to the DataFrame\n",
    "df['id'] = df.index + 1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9b08b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your MySQL password: ········\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "load_data_mySQL('MA5851_A3', 'xrp_price_yahoo', df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
