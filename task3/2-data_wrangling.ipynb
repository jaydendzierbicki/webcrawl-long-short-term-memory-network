{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13310b9b",
   "metadata": {},
   "source": [
    "# 2-Data Wrangling Script\n",
    "Date created: 16/04/23  \n",
    "Created by: Jayden Dzierbicki  \n",
    "Last updated: 16/04/23  \n",
    "\n",
    "The purpose of this notebook is to undertake the following in prepration for machine learning\n",
    "- Data wrangling and cleaning\n",
    "- NLP techniques \n",
    "- EDA\n",
    "- Clean data saved and stored into mySQL/csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d289a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "from sqlalchemy import create_engine # For connecting to SQL databases\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load data into mySQL\n",
    "def extract_data_mySQL(database_name, table_name):\n",
    "    user = 'root'\n",
    "\n",
    "    # Prompt the user for a password\n",
    "    password = getpass.getpass(\"Enter your MySQL password: \")\n",
    "    host = 'localhost'\n",
    "    port = 3306\n",
    "    database = database_name\n",
    "    engine = create_engine(f\"mysql+pymysql://{user}:{password}@{host}:{port}/{database}\")\n",
    "\n",
    "    # Write the DataFrame to a SQL table\n",
    "    table_name =  table_name\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "    \n",
    "    # Read query to dataframe\n",
    "    df = pd.read_sql(query, engine)\n",
    "    return(df)\n",
    "\n",
    "    # Close the connection\n",
    "    engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078f7195",
   "metadata": {},
   "source": [
    "## Data wrangling and cleaning\n",
    "- Load in data\n",
    "- Quick EDA of loaded data\n",
    "- Decsions based on EDA - period of analysis\n",
    "- Test and remove duplicates i.e. user could spam a forum board \n",
    "- NLP\n",
    "\n",
    "Decsions made in this section include:\n",
    "- Analysis from 2021-02-02 -> 2023-04-14: Limitations of data retrival for cryptocompare.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1b29f8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your MySQL password: Â·Â·Â·Â·Â·Â·Â·Â·\n",
      "Enter your MySQL password: Â·Â·Â·Â·Â·Â·Â·Â·\n",
      "Enter your MySQL password: Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    }
   ],
   "source": [
    "# Load in data sources\n",
    "cryptocompare_xrp = extract_data_mySQL('MA5851_A3', 'cryptocompare_xrp')\n",
    "investingcom_xrp = extract_data_mySQL('MA5851_A3', 'investingcom_xrp')\n",
    "xrp_price_yahoo = extract_data_mySQL('MA5851_A3', 'xrp_price_yahoo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7bfbb0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min and max date range of cryptocompare_xrp\n",
      "MIN Date: 2021-02-02\n",
      "MAX Date: 2023-04-14\n",
      "-----------------------------\n",
      "Min and max date range of investingcom_xrp\n",
      "MIN Date: 2018-03-16 00:00:00\n",
      "MAX Date: 2023-04-14 00:00:00\n",
      "-----------------------------\n",
      "Min and max date range of xrp_price_yahoo\n",
      "MIN Date: 2017-11-10 00:00:00\n",
      "MAX Date: 2023-04-14 00:00:00\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_min_max_dates(table, table_name):\n",
    "    print(f'Min and max date range of {table_name}')\n",
    "    print(f'MIN Date: {table.date.min()}')\n",
    "    print(f'MAX Date: {table.date.max()}')\n",
    "    print(\"-----------------------------\")\n",
    "\n",
    "\n",
    "get_min_max_dates(cryptocompare_xrp, \"cryptocompare_xrp\")\n",
    "get_min_max_dates(investingcom_xrp, \"investingcom_xrp\")\n",
    "get_min_max_dates(xrp_price_yahoo, \"xrp_price_yahoo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1596fc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows filtered by date from investingcom_xrp: 26268\n",
      "---------------------------------------------------------\n",
      "Number of rows filtered by date from xrp_price_yahoo: 1180\n",
      "---------------------------------------------------------\n",
      "Number of rows filtered by date from cryptocompare_xrp: 0\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Filter all data by date range, using data from 2021-02-02 onwards\n",
    "min_date_filter = pd.to_datetime('2021-02-02')  # Used to filter min date\n",
    "\n",
    "def filter_by_min_date(date_filter, df, table_name):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    filtered_df = df[df['date'] >= date_filter]\n",
    "    rows_removed = len(df) - len(filtered_df)\n",
    "    print(f\"Number of rows filtered by date from {table_name}: {rows_removed}\")\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    return filtered_df\n",
    "\n",
    "filtered_investingcom_xrp = filter_by_min_date(min_date_filter, investingcom_xrp, \"investingcom_xrp\")\n",
    "filtered_xrp_price_yahoo = filter_by_min_date(min_date_filter, xrp_price_yahoo, \"xrp_price_yahoo\")\n",
    "filtered_cryptocompare_xrp = filter_by_min_date(min_date_filter, cryptocompare_xrp, \"cryptocompare_xrp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "62df4b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NA rows removed from cryptocompare_xrp: 43\n",
      "---------------------------------------------------------\n",
      "Number of NA rows removed from investingcom_xrp: 129\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Remove NA observations from comments\n",
    "def remove_na_values(df, table_name, variable):\n",
    "    output = df.dropna(subset=[variable])\n",
    "    rows_removed = len(df) - len(output)\n",
    "    print(f\"Number of NA rows removed from {table_name}: {rows_removed}\")\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    return output\n",
    "\n",
    "# Assuming cryptocompare_xrp is a pandas DataFrame with a 'comment' column\n",
    "cleaned_cryptocompare_xrp = remove_na_values(filtered_investingcom_xrp, \"cryptocompare_xrp\", \"comment\")\n",
    "cleaned_investingcom_xrp = remove_na_values(filtered_cryptocompare_xrp, \"investingcom_xrp\", \"comment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bb39e39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate preview for cleaned_cryptocompare_xrp\n",
      "          date                                            comment  count\n",
      "124 2021-04-13                                                lol      6\n",
      "96  2021-04-10                                                lol      5\n",
      "38  2021-02-21                                            shut up      4\n",
      "105 2021-04-11  My newbie opinion: if price break 1.3200, it m...      4\n",
      "25  2021-02-14  Guys, how long do u suppose this place of resi...      4\n",
      "..         ...                                                ...    ...\n",
      "118 2021-04-13  Im not selling a penny till we beat the SEC an...      2\n",
      "117 2021-04-13                                   Here we go again      2\n",
      "116 2021-04-13                                              HODLğŸš€      2\n",
      "115 2021-04-13                                              Bitso      2\n",
      "337 2022-11-18  Exactly! Even 10% of swift business puts this ...      2\n",
      "\n",
      "[338 rows x 3 columns]\n",
      "-------------------------------------------------------------------------\n",
      "Duplicate preview for cleaned_investingcom_xrp\n",
      "        date                                            comment  count\n",
      "9 2022-01-22                                         #freeveyor      7\n",
      "0 2021-04-02  I want to Post a sun downer Photo of my flat b...      3\n",
      "1 2021-04-14                                              run..      2\n",
      "2 2021-05-04  Not the best start to a tuesday.. Iâ€™m still re...      2\n",
      "3 2021-05-08                          The moment of 1000 truths      2\n",
      "4 2021-05-16                                Today's a good day?      2\n",
      "5 2021-05-17                                                ;-)      2\n",
      "6 2021-06-29                Pump incoming\\t\\t\\t\\t\\t\\tView Edits      2\n",
      "7 2021-10-27                            .\\t\\t\\t\\t\\t\\tView Edits      2\n",
      "8 2021-12-22                                            Support      2\n",
      "-------------------------------------------------------------------------\n",
      "Number of duplicates removed from cleaned_cryptocompare_xrp: 375\n",
      "-------------------------------------------------------------------------\n",
      "Number of duplicates removed from cleaned_investingcom_xrp: 16\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def preview_duplicate_comments(df, table_name):\n",
    "    # Find duplicates based on 'date' and 'comment' columns\n",
    "    duplicates = df[df.duplicated(subset=['date', 'comment'], keep=False)]\n",
    "\n",
    "    # Group the duplicates by 'date' and 'comment' columns and count their occurrences\n",
    "    duplicate_counts = duplicates.groupby(['date', 'comment']).size().reset_index(name='count')\n",
    "\n",
    "    # Sort the DataFrame by the 'count' column in descending order\n",
    "    duplicate_counts_sorted = duplicate_counts.sort_values(by='count', ascending=False)\n",
    "\n",
    "    # Print the count for each specific duplicate\n",
    "    print(f\"Duplicate preview for {table_name}\")\n",
    "    print(duplicate_counts_sorted)\n",
    "    print(\"-------------------------------------------------------------------------\")\n",
    "\n",
    "def remove_duplicate_comments(df, table_name):\n",
    "    # Remove duplicates\n",
    "    unique_df = df.drop_duplicates(subset=['date', 'comment'])\n",
    "    duplicates_removed = len(df) - len(unique_df)\n",
    "    print(f'Number of duplicates removed from {table_name}: {duplicates_removed}')\n",
    "    print(\"-------------------------------------------------------------------------\")\n",
    "    return unique_df\n",
    "\n",
    "# Preview and remove duplicates\n",
    "preview_duplicate_comments(cleaned_cryptocompare_xrp, \"cleaned_cryptocompare_xrp\")\n",
    "preview_duplicate_comments(cleaned_investingcom_xrp, \"cleaned_investingcom_xrp\")\n",
    "\n",
    "cleaned_cryptocompare_xrp_2 = remove_duplicate_comments(cleaned_cryptocompare_xrp, \"cleaned_cryptocompare_xrp\")\n",
    "cleaned_investingcom_xrp_2 = remove_duplicate_comments(cleaned_investingcom_xrp, \"cleaned_investingcom_xrp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6d4b904a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of posts per day: 24.84\n",
      "Median number of posts per day: 8.50\n"
     ]
    }
   ],
   "source": [
    "# Join text data together retaining date, source and comment\n",
    "text_data = pd.concat([cleaned_investingcom_xrp_2, cleaned_cryptocompare_xrp_2])[['date', 'source', 'comment']]\n",
    "\n",
    "# create a new dataframe with the count of comments by date and source\n",
    "count_data = text_data.groupby(['date', 'source']).size().reset_index(name='count')\n",
    "\n",
    "# calculate the average number of posts per day - all sources\n",
    "avg_posts_per_day = count_data.groupby('date')['count'].mean().mean()\n",
    "print('Average number of posts per day: {:.2f}'.format(avg_posts_per_day))\n",
    "\n",
    "# calculate the median number of posts per day - all sources\n",
    "med_posts_per_day = count_data.groupby('date')['count'].median().median()\n",
    "print('Median number of posts per day: {:.2f}'.format(med_posts_per_day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a255a396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d6f1230e7c147b79834bba718201ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(DatePicker(value=Timestamp('2021-02-02 00:00:00'), description='Start date:'), DatePickeâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Qucik EDA to undertsand distrubtion of \n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive\n",
    "\n",
    "# define a function that plots the count of comments for a given date range\n",
    "def plot_comments(start_date, end_date):\n",
    "    start_date = np.datetime64(start_date)\n",
    "    end_date = np.datetime64(end_date)\n",
    "    data = count_data[(count_data['date'] >= start_date) & (count_data['date'] <= end_date)]\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    for source in data['source'].unique():\n",
    "        source_data = data[data['source'] == source]\n",
    "        ax.plot(source_data['date'], source_data['count'], label=source)\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Number of comments')\n",
    "    ax.set_title('Number of comments by source and date')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# create a date slider widget\n",
    "start_date_widget = widgets.DatePicker(description='Start date:', value=min(count_data['date']))\n",
    "end_date_widget = widgets.DatePicker(description='End date:', value=max(count_data['date']))\n",
    "\n",
    "# create an interactive plot using the date slider widget\n",
    "interactive_plot = interactive(plot_comments, start_date=start_date_widget, end_date=end_date_widget)\n",
    "output = interactive_plot.children[-1]\n",
    "output.layout.height = '400px'\n",
    "interactive_plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc86170f",
   "metadata": {},
   "source": [
    "### Graph Intepreation & Next steps:\n",
    "During the period between March and April of 2020-2021, there were significant developments in the legal battle between SEC and Ripple, which is reflected in the online forum discussions. This increase in discussions was particularly noticeable on the Cryptocompare platform, with a substantial spike during that period. For more information on the SEC vs. Ripple lawsuit, refer to this article: https://cointelegraph.com/learn/the-sec-vs-ripple-lawsuit-everything-you-need-to-know.\n",
    "\n",
    "#### At this stage we have commpleted the following tasks:\n",
    "- Filtered all data \n",
    "- Remove missing observations\n",
    "- Remove duplicates\n",
    "- Joined text data together & quick EDA of sample distrubtion\n",
    "\n",
    "#### The next stages will invlove:\n",
    "- Text cleanining (unwanted characters, HTML elements, conver to lower case etc)\n",
    "- Tokenization (Tokenize the text data into indivdual workds or tokens)\n",
    "- Stopword removal (debating as this can loose meaning of word)\n",
    "- Lemmatization or stemming (debating)\n",
    "- Embedding matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cdda2c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
